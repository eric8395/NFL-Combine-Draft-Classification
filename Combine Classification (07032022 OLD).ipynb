{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFL Combine Draft Classification  \n",
    "## A Logistic Regression Analysis\n",
    "\n",
    "### Eric Au\n",
    "\n",
    "<img src=\"https://library.sportingnews.com/styles/twitter_card_120x120/s3/2022-03/Antoine-Winfield-030222-GETTY-FTR.jpg?itok=nG3hUgf_\" width=\"500\" length = \"200\"/>\n",
    "\n",
    "Source: <a href=\"https://www.sportingnews.com/us/nfl/news/nfl-combine-drills-explained-40-yard-dash/lds11epxn7znufqyjkaphguq\">Getty Images</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business and Data Understanding\n",
    "\n",
    "Every year, the National Football League (NFL) holds a week long showcase where college football players, otherwise known as prospects, perform physical drills and tests in front of team coaches, scouts, and general managers. These drills are intended to measure a player's physical ability such as speed, quickness, strength, and overall athleticism. \n",
    "\n",
    "But what can NFL teams learn from these workouts? What exactly do the non-football athletic testing measurements contribute to prospect evaluation? These are a questions that many fans ask to this day and NFL teams try to interpret to make the best decision possible when drafting their players. \n",
    "\n",
    "For this analysis, we will be using player combine data scraped from <a href = \"https://www.pro-football-reference.com/\">Pro-Football Reference</a> over the last 22 years (2000-2022). \n",
    "\n",
    "Each record represents an individual player who was eligible to be drafted with information related to their combine measurements. Additionally, each record indicates whether that player was `Drafted` with 1 for \"Yes\" and 0 for \"No\". This will be further clarified in the preliminary cleaning of the data set. \n",
    "\n",
    "**The task is to predict whether a player was `Drafted` based on the available data and information provided in the NFL Combine.** \n",
    "\n",
    "**Stakeholders:** The New York Giants front office (General Manager, President, Scouting Department). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>School</th>\n",
       "      <th>College</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>40yd</th>\n",
       "      <th>Vertical</th>\n",
       "      <th>Bench</th>\n",
       "      <th>Broad Jump</th>\n",
       "      <th>3Cone</th>\n",
       "      <th>Shuttle</th>\n",
       "      <th>Drafted (tm/rnd/yr)</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Abraham</td>\n",
       "      <td>OLB</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6-4</td>\n",
       "      <td>252.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York Jets / 1st / 13th pick / 2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shaun Alexander</td>\n",
       "      <td>RB</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>College Stats</td>\n",
       "      <td>6-0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>4.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seattle Seahawks / 1st / 19th pick / 2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Darnell Alford</td>\n",
       "      <td>OT</td>\n",
       "      <td>Boston Col.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6-4</td>\n",
       "      <td>334.0</td>\n",
       "      <td>5.56</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>8.48</td>\n",
       "      <td>4.98</td>\n",
       "      <td>Kansas City Chiefs / 6th / 188th pick / 2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kyle Allamon</td>\n",
       "      <td>TE</td>\n",
       "      <td>Texas Tech</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6-2</td>\n",
       "      <td>253.0</td>\n",
       "      <td>4.97</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.0</td>\n",
       "      <td>7.29</td>\n",
       "      <td>4.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rashard Anderson</td>\n",
       "      <td>CB</td>\n",
       "      <td>Jackson State</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6-2</td>\n",
       "      <td>206.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.0</td>\n",
       "      <td>7.18</td>\n",
       "      <td>4.15</td>\n",
       "      <td>Carolina Panthers / 1st / 23rd pick / 2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player  Pos          School        College   Ht     Wt  40yd  \\\n",
       "0      John Abraham  OLB  South Carolina            NaN  6-4  252.0  4.55   \n",
       "1   Shaun Alexander   RB         Alabama  College Stats  6-0  218.0  4.58   \n",
       "2    Darnell Alford   OT     Boston Col.            NaN  6-4  334.0  5.56   \n",
       "3      Kyle Allamon   TE      Texas Tech            NaN  6-2  253.0  4.97   \n",
       "4  Rashard Anderson   CB   Jackson State            NaN  6-2  206.0  4.55   \n",
       "\n",
       "   Vertical  Bench  Broad Jump  3Cone  Shuttle  \\\n",
       "0       NaN    NaN         NaN    NaN      NaN   \n",
       "1       NaN    NaN         NaN    NaN      NaN   \n",
       "2      25.0   23.0        94.0   8.48     4.98   \n",
       "3      29.0    NaN       104.0   7.29     4.49   \n",
       "4      34.0    NaN       123.0   7.18     4.15   \n",
       "\n",
       "                            Drafted (tm/rnd/yr)  Year  \n",
       "0        New York Jets / 1st / 13th pick / 2000  2000  \n",
       "1     Seattle Seahawks / 1st / 19th pick / 2000  2000  \n",
       "2  Kansas City Chiefs / 6th / 188th pick / 2000  2000  \n",
       "3                                           NaN  2000  \n",
       "4    Carolina Panthers / 1st / 23rd pick / 2000  2000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in data\n",
    "df = pd.read_csv('Data/combine_2000_2022.csv', index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7680 entries, 0 to 7820\n",
      "Data columns (total 14 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Player               7680 non-null   object \n",
      " 1   Pos                  7680 non-null   object \n",
      " 2   School               7680 non-null   object \n",
      " 3   College              6240 non-null   object \n",
      " 4   Ht                   7651 non-null   object \n",
      " 5   Wt                   7656 non-null   float64\n",
      " 6   40yd                 7206 non-null   float64\n",
      " 7   Vertical             5932 non-null   float64\n",
      " 8   Bench                5096 non-null   float64\n",
      " 9   Broad Jump           5859 non-null   float64\n",
      " 10  3Cone                4792 non-null   float64\n",
      " 11  Shuttle              4895 non-null   float64\n",
      " 12  Drafted (tm/rnd/yr)  4937 non-null   object \n",
      " 13  Year                 7680 non-null   int64  \n",
      "dtypes: float64(7), int64(1), object(6)\n",
      "memory usage: 900.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Preparation\n",
    "### Convert to float types in appropriate columns; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of columns that need to be floats\n",
    "col_floats = ['Wt', '40yd', 'Vertical', 'Bench', 'Broad Jump', '3Cone', 'Shuttle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wt</th>\n",
       "      <th>40yd</th>\n",
       "      <th>Vertical</th>\n",
       "      <th>Bench</th>\n",
       "      <th>Broad Jump</th>\n",
       "      <th>3Cone</th>\n",
       "      <th>Shuttle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>252.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>218.0</td>\n",
       "      <td>4.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>334.0</td>\n",
       "      <td>5.56</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>8.48</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253.0</td>\n",
       "      <td>4.97</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.0</td>\n",
       "      <td>7.29</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>206.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.0</td>\n",
       "      <td>7.18</td>\n",
       "      <td>4.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7816</th>\n",
       "      <td>304.0</td>\n",
       "      <td>4.77</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7817</th>\n",
       "      <td>255.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7818</th>\n",
       "      <td>206.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7819</th>\n",
       "      <td>316.0</td>\n",
       "      <td>5.13</td>\n",
       "      <td>28.5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>4.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7820</th>\n",
       "      <td>215.0</td>\n",
       "      <td>4.88</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.0</td>\n",
       "      <td>7.19</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7680 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Wt  40yd  Vertical  Bench  Broad Jump  3Cone  Shuttle\n",
       "0     252.0  4.55       NaN    NaN         NaN    NaN      NaN\n",
       "1     218.0  4.58       NaN    NaN         NaN    NaN      NaN\n",
       "2     334.0  5.56      25.0   23.0        94.0   8.48     4.98\n",
       "3     253.0  4.97      29.0    NaN       104.0   7.29     4.49\n",
       "4     206.0  4.55      34.0    NaN       123.0   7.18     4.15\n",
       "...     ...   ...       ...    ...         ...    ...      ...\n",
       "7816  304.0  4.77      29.0    NaN       111.0    NaN      NaN\n",
       "7817  255.0   NaN       NaN    NaN         NaN    NaN      NaN\n",
       "7818  206.0   NaN       NaN   12.0         NaN    NaN      NaN\n",
       "7819  316.0  5.13      28.5   27.0       110.0   7.75     4.71\n",
       "7820  215.0  4.88      30.0    NaN       109.0   7.19     4.40\n",
       "\n",
       "[7680 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to type float for col_floats columns\n",
    "df[col_floats].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are 29 missing heights in the dataframe\n",
    "missing_heights = df[df['Ht'].isna()].index\n",
    "len(missing_heights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove these rows from the df\n",
    "df = df.drop(missing_heights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7651, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape (7680 - 29) = 7651\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert `Height` to appropriate float value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feet and inches columns to seperate the 'Ht'\n",
    "df['feet'] = df['Ht'].str.split(\"-\").str[0].astype(int)\n",
    "df['inches'] = df['Ht'].str.split(\"-\").str[1].astype(int)\n",
    "\n",
    "# add new Height column that calculates height as a float\n",
    "df['Height'] = df['feet'] + round((df['inches']/12),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unneeded columns and extra columns created\n",
    "df = df.drop(columns = ['Player', 'Ht', 'College','feet', 'inches'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns\n",
    "df = df[['Pos', 'School', 'Height', 'Wt', '40yd', 'Vertical', 'Bench',\n",
    "       'Broad Jump', '3Cone', 'Shuttle', 'Drafted (tm/rnd/yr)', 'Year']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create binary `Drafted ` Column of 1 - Yes, 0 - No if player was drafted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing in drafted column with 0\n",
    "df['Drafted (tm/rnd/yr)'] = df['Drafted (tm/rnd/yr)'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column Drafted that designates whether drafted (1) or not (0)\n",
    "df['Drafted'] = np.where(df['Drafted (tm/rnd/yr)'] == 0, 0, 1)\n",
    "\n",
    "# drop extra drafted column now\n",
    "df.drop(columns = 'Drafted (tm/rnd/yr)', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos</th>\n",
       "      <th>School</th>\n",
       "      <th>Height</th>\n",
       "      <th>Wt</th>\n",
       "      <th>40yd</th>\n",
       "      <th>Vertical</th>\n",
       "      <th>Bench</th>\n",
       "      <th>Broad Jump</th>\n",
       "      <th>3Cone</th>\n",
       "      <th>Shuttle</th>\n",
       "      <th>Year</th>\n",
       "      <th>Drafted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLB</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>6.33</td>\n",
       "      <td>252.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RB</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>6.00</td>\n",
       "      <td>218.0</td>\n",
       "      <td>4.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OT</td>\n",
       "      <td>Boston Col.</td>\n",
       "      <td>6.33</td>\n",
       "      <td>334.0</td>\n",
       "      <td>5.56</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>8.48</td>\n",
       "      <td>4.98</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TE</td>\n",
       "      <td>Texas Tech</td>\n",
       "      <td>6.17</td>\n",
       "      <td>253.0</td>\n",
       "      <td>4.97</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.0</td>\n",
       "      <td>7.29</td>\n",
       "      <td>4.49</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CB</td>\n",
       "      <td>Jackson State</td>\n",
       "      <td>6.17</td>\n",
       "      <td>206.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.0</td>\n",
       "      <td>7.18</td>\n",
       "      <td>4.15</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pos          School  Height     Wt  40yd  Vertical  Bench  Broad Jump  \\\n",
       "0  OLB  South Carolina    6.33  252.0  4.55       NaN    NaN         NaN   \n",
       "1   RB         Alabama    6.00  218.0  4.58       NaN    NaN         NaN   \n",
       "2   OT     Boston Col.    6.33  334.0  5.56      25.0   23.0        94.0   \n",
       "3   TE      Texas Tech    6.17  253.0  4.97      29.0    NaN       104.0   \n",
       "4   CB   Jackson State    6.17  206.0  4.55      34.0    NaN       123.0   \n",
       "\n",
       "   3Cone  Shuttle  Year  Drafted  \n",
       "0    NaN      NaN  2000        1  \n",
       "1    NaN      NaN  2000        1  \n",
       "2   8.48     4.98  2000        1  \n",
       "3   7.29     4.49  2000        0  \n",
       "4   7.18     4.15  2000        1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7651 entries, 0 to 7820\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Pos         7651 non-null   object \n",
      " 1   School      7651 non-null   object \n",
      " 2   Height      7651 non-null   float64\n",
      " 3   Wt          7651 non-null   float64\n",
      " 4   40yd        7191 non-null   float64\n",
      " 5   Vertical    5919 non-null   float64\n",
      " 6   Bench       5082 non-null   float64\n",
      " 7   Broad Jump  5850 non-null   float64\n",
      " 8   3Cone       4784 non-null   float64\n",
      " 9   Shuttle     4888 non-null   float64\n",
      " 10  Year        7651 non-null   int64  \n",
      " 11  Drafted     7651 non-null   int64  \n",
      "dtypes: float64(8), int64(2), object(2)\n",
      "memory usage: 777.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values in all the float columns\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check positions available\n",
    "df['Pos'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of offensive positions\n",
    "offense_list = ['WR', 'RB', 'OT', 'TE', 'QB', 'OG', 'C', 'OL', 'FB']\n",
    "\n",
    "# list of defensive positions\n",
    "defense_list = ['CB', 'S', 'DE', 'DT', 'OLB', 'ILB', 'LB', 'DL', 'EDGE', 'DB']\n",
    "\n",
    "# list of special team positions\n",
    "special_teams_list = ['LS', 'K', 'P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into offensive positions\n",
    "offense = df.loc[df['Pos'].isin(offense_list)]\n",
    "\n",
    "# split into defensive positions\n",
    "defense = df.loc[df['Pos'].isin(defense_list)]\n",
    "\n",
    "# split into special teams positions\n",
    "special_teams = df.loc[df['Pos'].isin(special_teams_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percent and count breakdowns\n",
    "# Offense\n",
    "total_offense = len(offense)\n",
    "total_offense_drafted = offense['Drafted'].value_counts()[1]\n",
    "total_offense_undrafted = offense['Drafted'].value_counts()[0]\n",
    "percent_off_drafted = round(offense['Drafted'].value_counts(normalize = True)[1], 2)\n",
    "percent_off_undrafted = round(offense['Drafted'].value_counts(normalize = True)[0], 2)\n",
    "\n",
    "print(\"Offense\")\n",
    "print(f\"Total Players:      {total_offense}\")\n",
    "print(f\"Total Drafted:      {total_offense_drafted}\")\n",
    "print(f\"Total Undrafted:    {total_offense_undrafted}\")\n",
    "print(f\"Percent Drafted:    {percent_off_drafted}\")\n",
    "print(f\"Percent Undrafted:  {percent_off_undrafted}\")\n",
    "print(\"-\"*25)\n",
    "\n",
    "# Defense\n",
    "total_defense = len(defense)\n",
    "total_defense_drafted = defense['Drafted'].value_counts()[1]\n",
    "total_defense_undrafted = defense['Drafted'].value_counts()[0]\n",
    "percent_def_drafted = round(defense['Drafted'].value_counts(normalize = True)[1], 2)\n",
    "percent_def_undrafted = round(defense['Drafted'].value_counts(normalize = True)[0], 2)\n",
    "\n",
    "print(\"Defense\")\n",
    "print(f\"Total Players:      {total_defense}\")\n",
    "print(f\"Total Drafted:      {total_defense_drafted}\")\n",
    "print(f\"Total Undrafted:    {total_defense_undrafted}\")\n",
    "print(f\"Percent Drafted:    {percent_def_drafted}\")\n",
    "print(f\"Percent Undrafted:  {percent_def_undrafted}\")\n",
    "print(\"-\"*25)\n",
    "\n",
    "# Special teams\n",
    "total_st = len(special_teams)\n",
    "total_st_drafted = special_teams['Drafted'].value_counts()[1]\n",
    "total_st_undrafted = special_teams['Drafted'].value_counts()[0]\n",
    "percent_st_drafted = round(special_teams['Drafted'].value_counts(normalize = True)[1], 2)\n",
    "percent_st_undrafted = round(special_teams['Drafted'].value_counts(normalize = True)[0], 2)\n",
    "\n",
    "print(\"Special Teams\")\n",
    "print(f\"Total Players:      {total_st}\")\n",
    "print(f\"Total Drafted:      {total_st_drafted}\")\n",
    "print(f\"Total Undrafted:    {total_st_undrafted}\")\n",
    "print(f\"Percent Drafted:    {percent_st_drafted}\")\n",
    "print(f\"Percent Undrafted:  {percent_st_undrafted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot visual breakdown of drafted by team category \n",
    "position_category = ['Offense', 'Defense', 'Special Teams']\n",
    "\n",
    "data = {'Drafted': [total_offense_drafted, total_defense_drafted, total_st_drafted],\n",
    "        'Undrafted': [total_offense_undrafted, total_defense_undrafted, total_st_undrafted]\n",
    "       }\n",
    "\n",
    "# create dataframe of positions & number of drafted\n",
    "drafted = pd.DataFrame(data,\n",
    "                       columns=['Undrafted', 'Drafted'], \n",
    "                       index = position_category)\n",
    "\n",
    "plt.style.use('seaborn-dark')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "drafted.plot(kind = 'barh',\n",
    "             edgecolor = \"black\",\n",
    "             linewidth = 1,\n",
    "             ax = ax, stacked = False,\n",
    "             xlim = (0, 3200))\n",
    "\n",
    "# create a list to collect the plt.patches data\n",
    "totals = []\n",
    "\n",
    "# find the values and append to list\n",
    "for i in ax.patches:\n",
    "    totals.append(i.get_width())\n",
    "\n",
    "# set individual bar lables using above list\n",
    "total = sum(totals)\n",
    "\n",
    "# set individual bar lables using above list\n",
    "for i in ax.patches:\n",
    "    # get_width pulls left or right; get_y pushes up or down\n",
    "    ax.text(i.get_width()+ 30, i.get_y() + 0.17, \\\n",
    "            str(round((i.get_width()/total)*100, 2))+'%', fontsize=10,\n",
    "color='black')\n",
    "\n",
    "# invert for largest on top \n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.title('Players Drafted by Team Category (2000-2022)', weight = \"bold\")\n",
    "plt.ylabel('Team Category')\n",
    "plt.xlabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drafted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict of drafted/undrafted with sums of each category\n",
    "total = ['']\n",
    "\n",
    "data = {'Undrafted': [drafted['Undrafted'].sum()],\n",
    "        'Drafted': [drafted['Drafted'].sum()]\n",
    "        }\n",
    "\n",
    "# new drafted_total df\n",
    "drafted_total = pd.DataFrame(data,\n",
    "                       columns=['Undrafted', 'Drafted'],\n",
    "                       index = total)\n",
    "\n",
    "plt.style.use('seaborn-dark')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "drafted_total.plot(kind = 'barh',\n",
    "             edgecolor = \"black\",\n",
    "             linewidth = 1,\n",
    "             ax = ax, stacked = True)\n",
    "\n",
    "# create a list to collect the plt.patches data\n",
    "totals = []\n",
    "\n",
    "# find the values and append to list\n",
    "for i in ax.patches:\n",
    "    totals.append(i.get_width())\n",
    "\n",
    "# set individual bar lables using above list\n",
    "total = sum(totals)\n",
    "\n",
    "# set individual bar lables using above list\n",
    "for i in ax.patches:\n",
    "    # get_width pulls left or right; get_y pushes up or down\n",
    "    ax.text(i.get_width()-900, i.get_y()+.21, \\\n",
    "            str(round((i.get_width()/total)*100, 2))+'%', \n",
    "            fontsize=15,\n",
    "            color='black')\n",
    "\n",
    "ax.set_xlabel('Count')\n",
    "\n",
    "ax.set(ylabel=None)\n",
    "ax.set_title('Drafted VS. Undrafted Players (2000-2022)', weight = \"bold\")\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drafted_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Drafted'], axis = 1)\n",
    "y = df['Drafted']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state= 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### may need to find average of each metric at combine for each position to fill in the NaNs after the train test split\n",
    "- fill NaNs with average for the position? or leave as 0?\n",
    "- check and discuss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_feature_train(X_train, feature_name):\n",
    "    \"\"\"\n",
    "    Helper function for transforming training data.  It takes in the full X dataframe and\n",
    "    feature name, makes a one-hot encoder, and returns the encoder as well as the dataframe\n",
    "    with that feature transformed into multiple columns of 1s and 0s\n",
    "    \"\"\"\n",
    "    # make a one-hot encoder and fit it to the training data\n",
    "    ohe = OneHotEncoder(categories=\"auto\", handle_unknown=\"ignore\")\n",
    "    single_feature_df = X_train[[feature_name]]\n",
    "    ohe.fit(single_feature_df)\n",
    "    \n",
    "    # call helper function that actually encodes the feature and concats it\n",
    "    X_train = encode_feature(X_train, feature_name, ohe)\n",
    "    \n",
    "    return ohe, X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_feature(X, feature_name, ohe):\n",
    "    \"\"\"\n",
    "    Helper function for transforming a feature into multiple columns of 1s and 0s. Used\n",
    "    in both training and testing steps.  Takes in the full X dataframe, feature name, \n",
    "    and encoder, and returns the dataframe with that feature transformed into multiple\n",
    "    columns of 1s and 0s\n",
    "    \"\"\"\n",
    "    # create new one-hot encoded df based on the feature\n",
    "    single_feature_df = X[[feature_name]]\n",
    "    feature_array = ohe.transform(single_feature_df).toarray()\n",
    "    ohe_df = pd.DataFrame(feature_array, columns=ohe.categories_[0], index=X.index)\n",
    "    \n",
    "    # drop the old feature from X and concat the new one-hot encoded df\n",
    "    X = X.drop(feature_name, axis=1)\n",
    "    X = pd.concat([X, ohe_df], axis=1)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish categorical feature names\n",
    "categorical_feature_names = ['Pos', 'School']\n",
    "\n",
    "# instantiates a ohe on the feature names\n",
    "encoders = {}\n",
    "\n",
    "for categorical_feature in categorical_feature_names:\n",
    "    ohe,X_train = encode_feature_train(X_train, categorical_feature)\n",
    "    encoders[categorical_feature] = ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model_more_iterations = LogisticRegression(random_state= 42, \n",
    "                                  penalty = 'none',\n",
    "                                  max_iter = 4000)\n",
    "logreg_model_more_iterations.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model_higher_tolerance = LogisticRegression(\n",
    "                                                random_state=2022, \n",
    "                                                penalty='none', \n",
    "                                                max_iter = 5000,\n",
    "                                                tol=60\n",
    ")\n",
    "\n",
    "logreg_model_higher_tolerance.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 6))\n",
    "\n",
    "axes[0].set_title(\"More Iterations\")\n",
    "axes[1].set_title(\"Higher Tolerance\")\n",
    "\n",
    "plot_confusion_matrix(logreg_model_more_iterations, X_train, y_train,\n",
    "                      ax=axes[0], cmap=\"plasma\")\n",
    "plot_confusion_matrix(logreg_model_higher_tolerance, X_train, y_train,\n",
    "                      ax=axes[1], cmap=\"plasma\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWithCV():\n",
    "    '''Structure to save the model and more easily see its crossvalidation'''\n",
    "    \n",
    "    def __init__(self, model, model_name, X, y, cv_now=True):\n",
    "        self.model = model\n",
    "        self.name = model_name\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        # For CV results\n",
    "        self.cv_results = None\n",
    "        self.cv_mean = None\n",
    "        self.cv_median = None\n",
    "        self.cv_std = None\n",
    "        #\n",
    "        if cv_now:\n",
    "            self.cross_validate()\n",
    "        \n",
    "    def cross_validate(self, X=None, y=None, kfolds=10):\n",
    "        '''\n",
    "        Perform cross-validation and return results.\n",
    "        \n",
    "        Args: \n",
    "          X:\n",
    "            Optional; Training data to perform CV on. Otherwise use X from object\n",
    "          y:\n",
    "            Optional; Training data to perform CV on. Otherwise use y from object\n",
    "          kfolds:\n",
    "            Optional; Number of folds for CV (default is 10)  \n",
    "        '''\n",
    "        \n",
    "        cv_X = X if X else self.X\n",
    "        cv_y = y if y else self.y\n",
    "\n",
    "        self.cv_results = cross_val_score(self.model, cv_X, cv_y, cv=kfolds)\n",
    "        self.cv_mean = np.mean(self.cv_results)\n",
    "        self.cv_median = np.median(self.cv_results)\n",
    "        self.cv_std = np.std(self.cv_results)\n",
    "\n",
    "        \n",
    "    def print_cv_summary(self):\n",
    "        cv_summary = (\n",
    "        f'''CV Results for `{self.name}` model:\n",
    "            {self.cv_mean:.5f} ± {self.cv_std:.5f} accuracy\n",
    "        ''')\n",
    "        print(cv_summary)\n",
    "\n",
    "        \n",
    "    def plot_cv(self, ax):\n",
    "        '''\n",
    "        Plot the cross-validation values using the array of results and given \n",
    "        Axis for plotting.\n",
    "        '''\n",
    "        ax.set_title(f'CV Results for `{self.name}` Model')\n",
    "        # Thinner violinplot with higher bw\n",
    "        sns.violinplot(y=self.cv_results, ax=ax, bw=.4)\n",
    "        sns.swarmplot(\n",
    "                y=self.cv_results,\n",
    "                color='orange',\n",
    "                size=10,\n",
    "                alpha= 0.8,\n",
    "                ax=ax\n",
    "        )\n",
    "\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model_more_iterations_results = ModelWithCV(\n",
    "                                        logreg_model_more_iterations,\n",
    "                                        'more_iterations',\n",
    "                                        X_train,\n",
    "                                        y_train\n",
    ")\n",
    "    \n",
    "logreg_model_higher_tolerance_results = ModelWithCV(\n",
    "                                        logreg_model_higher_tolerance,\n",
    "                                        'higher_tolerance',\n",
    "                                        X_train,\n",
    "                                        y_train\n",
    ")\n",
    "\n",
    "model_results = [\n",
    "    logreg_model_more_iterations_results,\n",
    "    logreg_model_higher_tolerance_results\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f,axes = plt.subplots(ncols=2, sharey=True, figsize=(12, 6))\n",
    "\n",
    "for ax, result in zip(axes, model_results):\n",
    "    ax = result.plot_cv(ax)\n",
    "    result.print_cv_summary()\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "plot_roc_curve(logreg_model_more_iterations, X_train, y_train, \n",
    "               name='logreg_model_more_iterations', ax=ax)\n",
    "plot_roc_curve(logreg_model_higher_tolerance, X_train, y_train, \n",
    "               name='logreg_model_higher_tolerance', ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep - Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to perform Feature Scaling when we are dealing with Gradient Descent Based algorithms (Linear and Logistic Regression, Neural Network) \n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_values(X, scaler):\n",
    "    \"\"\"\n",
    "    Given a DataFrame and a fitted scaler, use the scaler to scale all of the features\n",
    "    \"\"\"\n",
    "    scaled_array = scaler.transform(X)\n",
    "    scaled_df = pd.DataFrame(scaled_array, columns=X.columns, index=X.index)\n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scale_values(X_train, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3rd Model - After Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression(random_state=42)\n",
    "logreg_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.suptitle(\"Logistic Regression with Features Scaled\")\n",
    "\n",
    "plot_confusion_matrix(logreg_model, X_train_scaled, y_train, ax=ax, cmap=\"plasma\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features_results = ModelWithCV(\n",
    "                            logreg_model,\n",
    "                            'scaled_features',\n",
    "                            X_train_scaled,\n",
    "                            y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving variable for convenience\n",
    "model_results = scaled_features_results\n",
    "\n",
    "# Plot CV results\n",
    "fig, ax = plt.subplots()\n",
    "ax = model_results.plot_cv(ax)\n",
    "plt.tight_layout();\n",
    "# Print CV results\n",
    "model_results.print_cv_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(logreg_model, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
